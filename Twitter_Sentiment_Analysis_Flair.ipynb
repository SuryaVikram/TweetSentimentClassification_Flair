{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_Sentiment_Analysis_Flair",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SuryaVikram/TweetSentimentClassification_Flair/blob/master/Twitter_Sentiment_Analysis_Flair.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNzlbSeLhNMA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "\n",
        "\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxTYZTcahaXo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPky6UKahxym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download a file based on its file ID.\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = '10zQ2a7SzVJik1vdSnzPKbINPrs7CT7Si' ### File ID ###\n",
        "data = drive.CreateFile({'id': file_id})\n",
        "#print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3qBKq92jO-G",
        "colab_type": "code",
        "outputId": "edb7164b-07dd-4ad1-b8f5-5e60a2644e4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "import io\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "punctuation = string.punctuation\n",
        "data = pd.read_csv(io.StringIO(data.GetContentString())) \n",
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id                                              tweet\n",
              "0  31963  #studiolife #aislife #requires #passion #dedic...\n",
              "1  31964   @user #white #supremacists want everyone to s...\n",
              "2  31965  safe ways to heal your #acne!!    #altwaystohe...\n",
              "3  31966  is the hp and the cursed child book up for res...\n",
              "4  31967    3rd #bihday to my amazing, hilarious #nephew..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q7QMATvjbNi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def _clean(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"amp\", \"\", text)\n",
        "    #text = re.sub(r\"#\\w+\",\"\",text)\n",
        "    text = re.sub(r\"@\\w+\",\"\",text)\n",
        "    \n",
        "    \n",
        "    text = \"\".join(x for x in text if x not in punctuation)\n",
        "\n",
        "    L = [32, 44, 46, 65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,97,98,99,100,101,102,103, 104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122]\n",
        "    text = str(text)\n",
        "\n",
        "    return ''.join(i for i in text if ord(i) in L)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RCZusl1mS9-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['cleaned_tweet'] = data['tweet'].apply(_clean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpqOzzIwmk0j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "02e81d58-112c-4d36-c183-6fb2983e5c75"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>31963</td>\n",
              "      <td>#studiolife #aislife #requires #passion #dedic...</td>\n",
              "      <td>studiolife aislife requires passion dedication...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31964</td>\n",
              "      <td>@user #white #supremacists want everyone to s...</td>\n",
              "      <td>white supremacists want everyone to see the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>31965</td>\n",
              "      <td>safe ways to heal your #acne!!    #altwaystohe...</td>\n",
              "      <td>safe ways to heal your acne    altwaystoheal h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>31966</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "      <td>is the hp and the cursed child book up for res...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>31967</td>\n",
              "      <td>3rd #bihday to my amazing, hilarious #nephew...</td>\n",
              "      <td>rd bihday to my amazing hilarious nephew eli...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      id  ...                                      cleaned_tweet\n",
              "0  31963  ...  studiolife aislife requires passion dedication...\n",
              "1  31964  ...    white supremacists want everyone to see the ...\n",
              "2  31965  ...  safe ways to heal your acne    altwaystoheal h...\n",
              "3  31966  ...  is the hp and the cursed child book up for res...\n",
              "4  31967  ...    rd bihday to my amazing hilarious nephew eli...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2i8nF57mqM3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# download flair library #\n",
        "# import torch\n",
        "# !pip install flair\n",
        "# import flair"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP3-ATkcm2Zq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "41f137ce-dc95-458c-87fe-00a2a6e2cead"
      },
      "source": [
        "from flair.data import Sentence\n",
        "# create a sentence #\n",
        "sentence = Sentence('Blogs of Analytics Vidhya are Awesome.')\n",
        "# print the sentence to see what’s in it. #\n",
        "print(Sentence) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'flair.data.Sentence'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2YPgR1DnLKG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "108643ad-917b-4e38-cb58-8a087f76a4ea"
      },
      "source": [
        "#extracting the tweet part#\n",
        "text = data['cleaned_tweet'] \n",
        " ## txt is a list of tweets ##\n",
        "txt = text.tolist()\n",
        "print(txt[:10])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['studiolife aislife requires passion dedication willpower   to find newmaterials ', '  white supremacists want everyone to see the new   birds movie  and heres why  ', 'safe ways to heal your acne    altwaystoheal healthy   healing ', 'is the hp and the cursed child book up for reservations already if yes where if no when    harrypotter pottermore favorite', '  rd bihday to my amazing hilarious nephew eli ahmir uncle dave loves you and misses ', 'choose to be    momtips ', 'something inside me dies   eyes ness smokeyeyes tired  lonely sof grunge ', 'finishedtattooinkedinkloveit  thanksaleeee  ', '    i will never understand why my dad left me when i was so young  deep inthefeels  ', 'delicious   food lovelife capetown mannaepicure resturant ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwVh1ZfHnOQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Importing the Embeddings ##\n",
        "from flair.embeddings import WordEmbeddings\n",
        "from flair.embeddings import CharacterEmbeddings\n",
        "from flair.embeddings import StackedEmbeddings\n",
        "from flair.embeddings import FlairEmbeddings\n",
        "from flair.embeddings import BertEmbeddings\n",
        "from flair.embeddings import ELMoEmbeddings\n",
        "from flair.embeddings import FlairEmbeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZFP0uwfpJy1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "51ba9bb6-1f31-4c47-ea8b-5627b68ea973"
      },
      "source": [
        "### Initialising embeddings (un-comment to use others) ###\n",
        "#glove_embedding = WordEmbeddings('glove')\n",
        "#character_embeddings = CharacterEmbeddings()\n",
        "flair_forward  = FlairEmbeddings('news-forward-fast')\n",
        "flair_backward = FlairEmbeddings('news-backward-fast')\n",
        "#bert_embedding = BertEmbedding()\n",
        "#elmo_embedding = ElmoEmbedding()\n",
        "\n",
        "stacked_embeddings = StackedEmbeddings( embeddings = [ \n",
        "                                                       flair_forward, \n",
        "                                                       flair_backward\n",
        "                                                      ])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-04-28 21:31:52,995 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings/lm-news-english-backward-1024-v0.2rc.pt not found in cache, downloading to /tmp/tmppeqv9vpz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19689779/19689779 [00:02<00:00, 8969948.75B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2020-04-28 21:31:55,891 copying /tmp/tmppeqv9vpz to cache at /root/.flair/embeddings/lm-news-english-backward-1024-v0.2rc.pt\n",
            "2020-04-28 21:31:55,915 removing temp file /tmp/tmppeqv9vpz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JfpVVK9tFa5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "783fcff4-e60b-4f07-dc14-df46712e94e1"
      },
      "source": [
        "# create a sentence #\n",
        "sentence = Sentence(\"Analytics Vidhya blogs are Awesome .\")\n",
        "# embed words in sentence #\n",
        "stacked_embeddings.embed(sentence)\n",
        "for token in sentence:\n",
        "  print(token)\n",
        "  print(token.embedding.view(-1,))\n",
        "# data type and size of embedding #\n",
        "print(type(token.embedding))\n",
        "# storing size (length) #\n",
        "z = token.embedding.size()[0]\n",
        "print(z)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token: 1 Analytics\n",
            "tensor([-2.6460e-02, -8.3260e-04, -3.1604e-03,  ...,  2.2739e-09,\n",
            "        -2.2632e-08,  1.5214e-02])\n",
            "Token: 2 Vidhya\n",
            "tensor([-1.0809e-02, -7.1516e-05,  1.4545e-02,  ...,  5.8050e-09,\n",
            "        -3.6731e-09,  6.9285e-02])\n",
            "Token: 3 blogs\n",
            "tensor([-8.2266e-03, -1.1461e-04,  1.4814e-02,  ...,  3.8778e-09,\n",
            "         2.8023e-07, -9.3421e-02])\n",
            "Token: 4 are\n",
            "tensor([-1.1697e-02, -1.8518e-04,  1.9169e-02,  ...,  2.2128e-07,\n",
            "         3.2774e-09, -2.6248e-01])\n",
            "Token: 5 Awesome\n",
            "tensor([-8.7913e-03, -5.9724e-04, -3.8459e-03,  ...,  7.3547e-09,\n",
            "         5.5329e-09, -4.1644e-02])\n",
            "Token: 6 .\n",
            "tensor([ 2.7380e-04, -4.0641e-06,  1.8109e-03,  ...,  7.2283e-10,\n",
            "         1.9171e-07, -1.5373e-02])\n",
            "<class 'torch.Tensor'>\n",
            "2048\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}